# Introduction
This is the implementation of my master thesis, An Experimental Evaluation of A Deep Reinforcement Learning based Dynamic Portfolio Optimization and A Comparison with  Conventional Portfolio Optimization methods.
# Abstract
We explore the application of model-free deep reinforcement learning in portfolio optimization with the Proximal Policy Optimisation method (PPO) and study the effectiveness by comparing the performance against a wide range of models. As the European market is the least studied market, we have formulated the portfolio optimization problem into a model-free deep reinforcement learning(DRL) framework to allocate the constituents of the EUROSTOXX50. Further, we have studied the proximal policy optimization method to solve the DRL-based portfolio optimization problem since there are limited studies with the Actor-Critic approach in using reinforcement learning to the portfolio optimization problem. The PPO-based the model has shown relatively good performance with simple state representation, network structure and limited training budget. It shows the ability and flexibility of deep reinforcement learning methods to deal with a portfolio optimization problem and potentially outperform with more advanced state representation and complex network structure.
# Workflow and structure
Notebook are indexed with numbers, an overview of the details of the notebook could be found in FileOverview.xlsx. It is simple to run on colab by cloning the repo, a list of dependency is attached in RequirementList.txt if you want to run it locally.

